---
layout: post
title: "Machine Learning / Reinforcement Learning Work"
date: 2021-12-08
excerpt: "Coursework from CS229 and CS238/AA228 at Stanford"
tags: [coursework]
feature: /assets/img/stanford_s.png
comments: false
project: true
---

# CS 229: Machine Learning

Introduction:

Over the past two years, the public eye has been focused on one key dataset: COVID case numbers. Yet, trends in COVID-19 case numbers have been relatively diffcult to predict due to the many dependent factors and the unpredictability of human behavior. While many machine learning approaches have been taken to model and predict these disease trends, we approach this by incorporating Google trends data for pandemic-related search queries, in the hopes that this is a valuable metric for relating human behavior to the prediction of COVID-19 case counts. In this project, we explore the effectiveness of three model types in predicting COVID-19 trends using search query frequency data: multivariate linear regression, random forest regression, and long short-term memory (LSTM)

[Access the report PDF](/pdfs/CS229report.pdf){: .btn}
[Go to the GitHub repo](https://github.com/danielpmorton/CS229_FinalProject)


# CS 238 / AA228: Decision Making Under Uncertainty

Abstract:

This work applies reinforcement learning to the game of Fantasy Football. Fantasy football is a game where human agents receive points each week based on how well American Football players on their fctitious roster perform in the National Football League (NFL) each week. The uncertainty present in both actual and fantasy football leads to the problem of how an agent playing fantasy football can prioritize diﬀerent football positions and sequentially make lineup changes to a fantasy roster each week in order to maximize performance over the course of an NFL season. We formatted this problem as a Markov Decision Process (MDP) and employed a model-free approach using Q-learning to learn the optimal roster decision policy. To accomplish this, the problem space was constrained to three player positions, and a limited set of actions that involved swapping players with others at their position or keeping the same roster for the week. Also, a reward function was developed based on both the relative performance of the new roster compared to the previous roster and transaction costs for player swaps. Once completed, the model was trained on multiple seasons of fantasy football data. The policy generated from the trained model was able to outperform a baseline random policy the majority of the time when tested on diﬀerent NFL seasons.

[Access the report PDF](/pdfs/AA228report.pdf){: .btn}
[Go to the GitHub repo](https://github.com/danielpmorton/AA228-Final-Project)
